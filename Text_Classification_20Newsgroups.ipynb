{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification on 20Newsgroups\n",
    "\n",
    "In this tutorial you'll learn to classify the [20Newsgroups](http://qwone.com/~jason/20Newsgroups/) dataset and compare the performance of STC with standard classifiers.\n",
    "\n",
    "\n",
    "## Colab\n",
    "\n",
    "This tutorial and the rest in [this sequence](https://github.com/SparseTensorClassifier/tutorial) can be done in Google colab. If you'd like to open this notebook in colab, you can use the following link or click [here](https://colab.research.google.com/github/SparseTensorClassifier/tutorial/blob/main/Text_Classification_20Newsgroups.ipynb).\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SparseTensorClassifier/tutorial/blob/main/Text_Classification_20Newsgroups.ipynb)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Uncomment and run the following cell to install the packages. Then, import the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stc pandas numpy scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics as mtr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from stc import SparseTensorClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the 20news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = fetch_20newsgroups(subset='train')\n",
    "data_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the competing algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train and test sets\n",
    "\n",
    "Use a simple tokenization with `nltk.word_tokenize` and vectorize with Tf-Idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "y_train, y_test = data_train.target, data_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Logistic Regression\n",
      "Training: Support Vector Machine\n",
      "Training: Multinomial Naive Bayes\n",
      "Training: Decision Tree\n",
      "Training: Random Forest\n",
      "Training: K-Nearest Neighbors\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(\"Training: {}\".format(model_name))\n",
    "    models[model_name].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: Logistic Regression\n",
      "Predicting: Support Vector Machine\n",
      "Predicting: Multinomial Naive Bayes\n",
      "Predicting: Decision Tree\n",
      "Predicting: Random Forest\n",
      "Predicting: K-Nearest Neighbors\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for model_name, model in models.items():\n",
    "    print(\"Predicting: {}\".format(model_name))\n",
    "    predictions[model_name] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for SparseTensorClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a simple tokenization with `nltk.word_tokenize` and convert to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_train, json_test = [], []\n",
    "for i, doc in list(enumerate(data_train.data)):\n",
    "    json_train.append({'words': nltk.word_tokenize(doc), 'target': [data_train.target[i]]})\n",
    "for i, doc in list(enumerate(data_test.data)):\n",
    "    json_test.append({'words': nltk.word_tokenize(doc)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.0% Fitting (00:01:05.25/00:01:05.25)\r"
     ]
    }
   ],
   "source": [
    "STC = SparseTensorClassifier(features=['words'], targets=['target'])\n",
    "STC.fit(json_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.0% Predicting (00:01:12.59/00:01:12.59)\r"
     ]
    }
   ],
   "source": [
    "labels, _, _ = STC.predict(json_test, probability=False, explain=False)\n",
    "predictions['Sparse Tensor Classifier'] = labels.target.values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = []\n",
    "for estimator, y_pred in predictions.items():\n",
    "    report = mtr.classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    E.append({\n",
    "        'Model': estimator, 'Accuracy': report['accuracy'],\n",
    "        'Avg Precision (macro)': report['macro avg']['precision'],\n",
    "        'Avg Recall (macro)': report['macro avg']['recall'],\n",
    "        'Avg F1-score (macro)': report['macro avg']['f1-score'],\n",
    "        'Avg Precision (weighted)': report['weighted avg']['precision'],\n",
    "        'Avg Recall (weighted)': report['weighted avg']['recall'],\n",
    "        'Avg F1-score (weighted)': report['weighted avg']['f1-score']\n",
    "    })\n",
    "E = pd.DataFrame(E).set_index('Model', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Avg Precision (macro)</th>\n",
       "      <th>Avg Recall (macro)</th>\n",
       "      <th>Avg F1-score (macro)</th>\n",
       "      <th>Avg Precision (weighted)</th>\n",
       "      <th>Avg Recall (weighted)</th>\n",
       "      <th>Avg F1-score (weighted)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.797663</td>\n",
       "      <td>0.802854</td>\n",
       "      <td>0.787721</td>\n",
       "      <td>0.789587</td>\n",
       "      <td>0.804665</td>\n",
       "      <td>0.797663</td>\n",
       "      <td>0.796521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.777217</td>\n",
       "      <td>0.790612</td>\n",
       "      <td>0.768136</td>\n",
       "      <td>0.772872</td>\n",
       "      <td>0.793172</td>\n",
       "      <td>0.777217</td>\n",
       "      <td>0.779243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.735661</td>\n",
       "      <td>0.816400</td>\n",
       "      <td>0.716682</td>\n",
       "      <td>0.717503</td>\n",
       "      <td>0.811408</td>\n",
       "      <td>0.735661</td>\n",
       "      <td>0.732126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.536511</td>\n",
       "      <td>0.530171</td>\n",
       "      <td>0.529172</td>\n",
       "      <td>0.528790</td>\n",
       "      <td>0.537341</td>\n",
       "      <td>0.536511</td>\n",
       "      <td>0.536033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.747345</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.735418</td>\n",
       "      <td>0.733717</td>\n",
       "      <td>0.759892</td>\n",
       "      <td>0.747345</td>\n",
       "      <td>0.741517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.523898</td>\n",
       "      <td>0.592446</td>\n",
       "      <td>0.522290</td>\n",
       "      <td>0.533538</td>\n",
       "      <td>0.600985</td>\n",
       "      <td>0.523898</td>\n",
       "      <td>0.538897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sparse Tensor Classifier</th>\n",
       "      <td>0.863516</td>\n",
       "      <td>0.862865</td>\n",
       "      <td>0.855559</td>\n",
       "      <td>0.855650</td>\n",
       "      <td>0.865961</td>\n",
       "      <td>0.863516</td>\n",
       "      <td>0.861457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy  Avg Precision (macro)  Avg Recall (macro)  \\\n",
       "Model                                                                           \n",
       "Logistic Regression       0.797663               0.802854            0.787721   \n",
       "Support Vector Machine    0.777217               0.790612            0.768136   \n",
       "Multinomial Naive Bayes   0.735661               0.816400            0.716682   \n",
       "Decision Tree             0.536511               0.530171            0.529172   \n",
       "Random Forest             0.747345               0.761500            0.735418   \n",
       "K-Nearest Neighbors       0.523898               0.592446            0.522290   \n",
       "Sparse Tensor Classifier  0.863516               0.862865            0.855559   \n",
       "\n",
       "                          Avg F1-score (macro)  Avg Precision (weighted)  \\\n",
       "Model                                                                      \n",
       "Logistic Regression                   0.789587                  0.804665   \n",
       "Support Vector Machine                0.772872                  0.793172   \n",
       "Multinomial Naive Bayes               0.717503                  0.811408   \n",
       "Decision Tree                         0.528790                  0.537341   \n",
       "Random Forest                         0.733717                  0.759892   \n",
       "K-Nearest Neighbors                   0.533538                  0.600985   \n",
       "Sparse Tensor Classifier              0.855650                  0.865961   \n",
       "\n",
       "                          Avg Recall (weighted)  Avg F1-score (weighted)  \n",
       "Model                                                                     \n",
       "Logistic Regression                    0.797663                 0.796521  \n",
       "Support Vector Machine                 0.777217                 0.779243  \n",
       "Multinomial Naive Bayes                0.735661                 0.732126  \n",
       "Decision Tree                          0.536511                 0.536033  \n",
       "Random Forest                          0.747345                 0.741517  \n",
       "K-Nearest Neighbors                    0.523898                 0.538897  \n",
       "Sparse Tensor Classifier               0.863516                 0.861457  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! \n",
    "\n",
    "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with SparseTensorClassifier, we encourage you to finish the rest of the tutorials in [this series](https://github.com/SparseTensorClassifier/tutorial). Don't forget to star the [repository](https://github.com/SparseTensorClassifier/stc)! \n",
    "\n",
    "[![GitHub Repo stars](https://img.shields.io/github/stars/SparseTensorClassifier/stc?style=social)](https://github.com/SparseTensorClassifier/stc)\n",
    "\n",
    "Thanks by https://sparsetensorclassifier.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
